{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "60b73c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "import json\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.width', 0)\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "import fitz  # PyMuPDF\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8cc5d01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = fitz.open(\"D:/GenAI/Cold_Email_Generator/app/resource/Saqib Alam Ansari Resume.pdf\")\n",
    "text = \"\"\n",
    "for page in doc:\n",
    "    text += page.get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "669f461d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saqib Alam Ansari \\n+(91) 9999473710 | saqibdatascience@gmail.com | Delhi, India | LinkedIn \\n \\nExperience \\nZuno General Insurance | Mumbai, Maharashtra (Remote) \\nData Science Intern | 03/2024 – 06/2024 \\n• Worked on different projects like Motor Renewal Analytics, Loss Ratio Analysis, Motor Fraud Detection. \\n• Understand domain and workflow of insurance company and data understanding by hovering Multiple Data Views \\nextracted from SAP Hana which can be utilized in analysis and model building. \\n• Build best Motor Fraud Detection Model, outperforming existing model with 0.80 recall, and 0.40 f1-score. \\n• Comparing Financial Years, to make decisions for business for growing in future and areas of focus, either state- \\nwise, product-wise, service-wise, tried to find out patterns by which we company can grow. \\n \\nAspire Fintech Private Limited | Bengaluru, Karnataka (Remote) \\nData Science Intern | 02/2023 – 10/2023 \\n• Worked on 6 different projects during internship in growth and performance perspectives \\n• Applied ML techniques to analyze bureau data from 120,000 users, effectively reducing fraud risks \\n• Engineered 1000+ features using NumPy, Pandas, regex from OTP, SMS, Payday, and Fintech data present in \\nMySQL database to reduce risk by adding these features to existing machine learning model and measuring the \\nimpact of new features \\n• Enhanced existing files by adding 600+ Entities and 4300+ Headers, facilitating better data organization \\n• Developed a specialized ML model using data from 6000+ rejected/delinquent users to tailor credit offerings \\n• Implemented multiple models to minimizing risk exposure effectively and ensuring robustness of model by \\nselecting optimum set of model features using RFE, Stability Selection and Boruta algorithms with cross-validation \\niNeuron.ai | Bangaluru, Karnataka (Remote) \\nData Science Project Intern | 04/2022 – 07/2022 \\n• Analyzed $186.19M in Amazon sales data in Tableau for actionable insights with Data Preprocessing \\n• Derived detailed sales insights by state, country, product, and time period \\n• Identified top and worst performing products for strategic planning \\nProjects \\nEnd-to-End ML Project for Water Potability \\n• Performed Preprocessing, EDA, Feature Engineering on data for making it model building ready \\n• Utilized multiple data preprocessing techniques in imputation, imbalance handling, feature creation etc. \\n• Performed null values imputation using Linear Regression with non-null columns to predicting null values \\n• Built ML models like Logistic Regression, Decision Tree, KNN, Random Forest, SVM, Artificial Neural Network \\n• Performed hyperparameter tuning using Grid Seach CV resulting 72% F1 score \\n• Published a conference paper on this project in IEEE 10th International Conference \\nStock Analyzing Using AI Agents \\n• Real-Time Market Intelligence: Using Agent 1 to analyze industry-specific news, ensuring timely stock market \\ninsights.  \\n• Expert Stock Recommendations: Using Agent 2, curates the top 5 stock picks based on AI-driven analysis. \\n• AI-Powered Workflow: Leverages AI Agents, Crew AI, and Serper to automate stock research, enhancing \\nprecision and efficiency. \\n• Seamless AI Integration: Combines multi-agent collaboration to deliver a streamlined and intelligent stock \\nrecommendation experience. GITHUB \\nSkills \\nFrameworks & Tools: NumPy, Pandas, Scikit-learn, Langchain, MySQL, Seaborn, TensorFlow, PowerBI  \\nSkills: Python, Excel, Statistics, Data Analysis, Machine Learning, Deep Learning, LLMs, Hugging Face, Ollama, Groq  \\nEducation \\nMaharishi University of Information Technology                                                        Noida, Delhi NCR | 2020 – June, 2024 \\nB. Tech: Computer Science in Data Science                                                                                    Aggregated CGPA: 9.0 \\nCertifications \\n \\nData Science Specialization, Internshala \\n'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d814fb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import clean_text\n",
    "cleaned_text = clean_text(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb24f360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Saqib Alam Ansari 91 9999473710 saqibdatasciencegmailcom Delhi India LinkedIn Experience Zuno General Insurance Mumbai Maharashtra Remote Data Science Intern 032024 062024 Worked on different projects like Motor Renewal Analytics Loss Ratio Analysis Motor Fraud Detection Understand domain and workflow of insurance company and data understanding by hovering Multiple Data Views extracted from SAP Hana which can be utilized in analysis and model building Build best Motor Fraud Detection Model outperforming existing model with 080 recall and 040 f1score Comparing Financial Years to make decisions for business for growing in future and areas of focus either state wise productwise servicewise tried to find out patterns by which we company can grow Aspire Fintech Private Limited Bengaluru Karnataka Remote Data Science Intern 022023 102023 Worked on 6 different projects during internship in growth and performance perspectives Applied ML techniques to analyze bureau data from 120000 users effectively reducing fraud risks Engineered 1000 features using NumPy Pandas regex from OTP SMS Payday and Fintech data present in MySQL database to reduce risk by adding these features to existing machine learning model and measuring the impact of new features Enhanced existing files by adding 600 Entities and 4300 Headers facilitating better data organization Developed a specialized ML model using data from 6000 rejecteddelinquent users to tailor credit offerings Implemented multiple models to minimizing risk exposure effectively and ensuring robustness of model by selecting optimum set of model features using RFE Stability Selection and Boruta algorithms with crossvalidation iNeuronai Bangaluru Karnataka Remote Data Science Project Intern 042022 072022 Analyzed 18619M in Amazon sales data in Tableau for actionable insights with Data Preprocessing Derived detailed sales insights by state country product and time period Identified top and worst performing products for strategic planning Projects EndtoEnd ML Project for Water Potability Performed Preprocessing EDA Feature Engineering on data for making it model building ready Utilized multiple data preprocessing techniques in imputation imbalance handling feature creation etc Performed null values imputation using Linear Regression with nonnull columns to predicting null values Built ML models like Logistic Regression Decision Tree KNN Random Forest SVM Artificial Neural Network Performed hyperparameter tuning using Grid Seach CV resulting 72 F1 score Published a conference paper on this project in IEEE 10th International Conference Stock Analyzing Using AI Agents RealTime Market Intelligence Using Agent 1 to analyze industryspecific news ensuring timely stock market insights Expert Stock Recommendations Using Agent 2 curates the top 5 stock picks based on AIdriven analysis AIPowered Workflow Leverages AI Agents Crew AI and Serper to automate stock research enhancing precision and efficiency Seamless AI Integration Combines multiagent collaboration to deliver a streamlined and intelligent stock recommendation experience GITHUB Skills Frameworks Tools NumPy Pandas Scikitlearn Langchain MySQL Seaborn TensorFlow PowerBI Skills Python Excel Statistics Data Analysis Machine Learning Deep Learning LLMs Hugging Face Ollama Groq Education Maharishi University of Information Technology Noida Delhi NCR 2020 June 2024 B Tech Computer Science in Data Science Aggregated CGPA 90 Certifications Data Science Specialization Internshala'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b52ff461",
   "metadata": {},
   "outputs": [],
   "source": [
    "groq_api = os.getenv('GROQ_API_KEY')\n",
    "llm = ChatGroq(temperature=0, groq_api_key=groq_api, model_name=\"llama-3.3-70b-versatile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bff3c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt_extract = PromptTemplate.from_template('''\n",
    "# You are an AI bot designed to act as a professional for parsing resumes. You are given with resume and your job is to extract the following information from the resume:\n",
    "\n",
    "# 1. Full Name\n",
    "# 2. Email Address\n",
    "# 3. Phone Number\n",
    "# 2. employment details (just company name and its duration)\n",
    "# 3. technical skills (either present in dedicated section or in projects worked on)\n",
    "# 4. Projects worked on summary (seperate column or section for each project's description with all quantitative details)\n",
    "# 5. education details\n",
    "# 6. certifications\n",
    "\n",
    "# Resume:\n",
    "# {resume}\n",
    "# Only return the valid JSON, not a single word more.\n",
    "# NO PREAMBLE  \n",
    "# ''')\n",
    "\n",
    "# chain_extract = prompt_extract | llm\n",
    "# res = chain_extract.invoke({\"resume\": cleaned_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "7148593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_extract = PromptTemplate.from_template('''\n",
    "You are an AI bot designed to act as a professional for parsing resumes. You are given with resume and your job is to extract the following information from the resume:\n",
    "\n",
    "1. Full Name\n",
    "2. Email Address\n",
    "3. Phone Number\n",
    "2. employment details (just company name and its duration)\n",
    "3. technical skills (either present in dedicated section or in projects worked on)\n",
    "4. Projects worked on summary (seperate column or section for each project's description with all quantitative details)\n",
    "5. education details\n",
    "6. certifications\n",
    "\n",
    "Resume:\n",
    "{resume}\n",
    "#Only return the valid text file format\n",
    "Example :\n",
    "Full Name\n",
    "Name of user\n",
    "NO PREAMBLE  \n",
    "''')\n",
    "\n",
    "chain_extract = prompt_extract | llm\n",
    "resume_extract = chain_extract.invoke({\"resume\": cleaned_text})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3203c5c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Full Name\\nSaqib Alam Ansari\\n\\nEmail Address\\nsaqibdatascience@gmail.com\\n\\nPhone Number\\n91 9999473710\\n\\nEmployment Details\\nZuno General Insurance, 03/2024 - 06/2024\\nAspire Fintech Private Limited, 02/2023 - 10/2023\\niNeuronai, 04/2022 - 07/2022\\n\\nTechnical Skills\\nNumPy, Pandas, Scikit-learn, Langchain, MySQL, Seaborn, TensorFlow, PowerBI, Python, Excel, Statistics, Data Analysis, Machine Learning, Deep Learning, LLMs, Hugging Face, Ollama, Groq\\n\\nProjects Worked On\\n### Project 1: Motor Renewal Analytics\\nWorked on different projects like Motor Renewal Analytics, Loss Ratio Analysis, Motor Fraud Detection\\nUnderstand domain and workflow of insurance company and data understanding by hovering Multiple Data Views extracted from SAP Hana\\nBuild best Motor Fraud Detection Model outperforming existing model with 0.80 recall and 0.40 f1score\\n\\n### Project 2: Aspire Fintech Private Limited\\nWorked on 6 different projects during internship in growth and performance perspectives\\nApplied ML techniques to analyze bureau data from 120,000 users effectively reducing fraud risks\\nEngineered 1000 features using NumPy, Pandas, regex from OTP, SMS, Payday, and Fintech data present in MySQL database to reduce risk\\nEnhanced existing files by adding 600 Entities and 4300 Headers facilitating better data organization\\nDeveloped a specialized ML model using data from 6000 rejected/delinquent users to tailor credit offerings\\n\\n### Project 3: iNeuronai\\nAnalyzed $18.619M in Amazon sales data in Tableau for actionable insights with Data Preprocessing\\nDerived detailed sales insights by state, country, product, and time period\\nIdentified top and worst performing products for strategic planning\\n\\n### Project 4: End-to-End ML Project for Water Potability\\nPerformed Preprocessing, EDA, Feature Engineering on data for making it model building ready\\nUtilized multiple data preprocessing techniques in imputation, imbalance handling, feature creation, etc\\nPerformed null values imputation using Linear Regression with non-null columns to predicting null values\\nBuilt ML models like Logistic Regression, Decision Tree, KNN, Random Forest, SVM, Artificial Neural Network\\nPerformed hyperparameter tuning using Grid Search CV resulting 0.72 F1 score\\n\\n### Project 5: Stock Analyzing Using AI Agents\\nReal-Time Market Intelligence Using Agent 1 to analyze industry-specific news ensuring timely stock market insights\\nExpert Stock Recommendations Using Agent 2 curates the top 5 stock picks based on AI-driven analysis\\nAI-Powered Workflow Leverages AI Agents Crew AI and Serper to automate stock research enhancing precision and efficiency\\nSeamless AI Integration Combines multi-agent collaboration to deliver a streamlined and intelligent stock recommendation experience\\n\\nEducation Details\\nMaharishi University of Information Technology, Noida, Delhi NCR, 2020 - June 2024\\nB.Tech Computer Science in Data Science, Aggregated CGPA: 9.0\\n\\nCertifications\\nData Science Specialization, Internshala'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resume_extract.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b6c647e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def post_json_preprocess(json_str):\n",
    "#     try:\n",
    "#         json_str = res.content.strip().strip('```')\n",
    "#         # Attempt to parse the JSON string\n",
    "#         parsed_json = json.loads(json_str)\n",
    "#     except json.JSONDecodeError:\n",
    "#         # If parsing fails, return an empty dictionary or handle the error as needed\n",
    "#         return pd.DataFrame()\n",
    "    \n",
    "#     # Check if the parsed data is a dictionary\n",
    "#     if isinstance(parsed_json, dict):\n",
    "        \n",
    "#         df = pd.json_normalize(parsed_json)\n",
    "#         return df\n",
    "#     else:\n",
    "#         return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0db0be8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Name</th>\n",
       "      <th>Email Address</th>\n",
       "      <th>Phone Number</th>\n",
       "      <th>Employment Details</th>\n",
       "      <th>Technical Skills</th>\n",
       "      <th>Projects</th>\n",
       "      <th>Education Details</th>\n",
       "      <th>Certifications</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Saqib Alam Ansari</td>\n",
       "      <td>saqibdatascience@gmail.com</td>\n",
       "      <td>91 9999473710</td>\n",
       "      <td>[{'Company Name': 'Zuno General Insurance', 'Duration': '03/2024 - 06/2024'}, {'Company Name': 'Aspire Fintech Private Limited', 'Duration': '02/2023 - 10/2023'}, {'Company Name': 'iNeuronai', 'Duration': '04/2022 - 07/2022'}]</td>\n",
       "      <td>[NumPy, Pandas, Scikit-learn, Langchain, MySQL, Seaborn, TensorFlow, PowerBI, Python, Excel, Statistics, Data Analysis, Machine Learning, Deep Learning, LLMs, Hugging Face, Ollama, Groq]</td>\n",
       "      <td>[{'Project Name': 'Motor Renewal Analytics', 'Description': 'Worked on different projects like Motor Renewal Analytics, Loss Ratio Analysis, Motor Fraud Detection. Built best Motor Fraud Detection Model outperforming existing model with 0.80 recall and 0.40 f1-score.'}, {'Project Name': 'Bureau Data Analysis', 'Description': 'Applied ML techniques to analyze bureau data from 120,000 users effectively reducing fraud risks. Engineered 1000 features using NumPy, Pandas, regex from OTP, SMS, Payday, and Fintech data present in MySQL database to reduce risk by adding these features to existing machine learning model and measuring the impact of new features.'}, {'Project Name': 'End-to-End ML Project for Water Potability', 'Description': 'Performed Preprocessing, EDA, Feature Engineering on data for making it model building ready. Utilized multiple data preprocessing techniques in imputation, imbalance handling, feature creation, etc. Performed null values imputation using Linear Regression with non-null columns to predicting null values. Built ML models like Logistic Regression, Decision Tree, KNN, Random Forest, SVM, Artificial Neural Network. Performed hyperparameter tuning using Grid Search CV resulting 0.72 F1 score.'}, {'Project Name': 'Stock Analyzing Using AI Agents', 'Description': 'Real-Time Market Intelligence Using Agent 1 to analyze industry-specific news ensuring timely stock market insights. Expert Stock Recommendations Using Agent 2 curates the top 5 stock picks based on AI-driven analysis. AI-Powered Workflow Leverages AI Agents Crew AI and Serper to automate stock research enhancing precision and efficiency. Seamless AI Integration Combines multi-agent collaboration to deliver a streamlined and intelligent stock recommendation experience.'}]</td>\n",
       "      <td>[{'University Name': 'Maharishi University of Information Technology', 'Location': 'Noida, Delhi NCR', 'Degree': 'B.Tech Computer Science in Data Science', 'CGPA': '9.0', 'Graduation Date': 'June 2024'}]</td>\n",
       "      <td>[{'Certification Name': 'Data Science Specialization', 'Issuing Organization': 'Internshala'}]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Full Name               Email Address   Phone Number  \\\n",
       "0  Saqib Alam Ansari  saqibdatascience@gmail.com  91 9999473710   \n",
       "\n",
       "                                                                                                                                                                                                                   Employment Details  \\\n",
       "0  [{'Company Name': 'Zuno General Insurance', 'Duration': '03/2024 - 06/2024'}, {'Company Name': 'Aspire Fintech Private Limited', 'Duration': '02/2023 - 10/2023'}, {'Company Name': 'iNeuronai', 'Duration': '04/2022 - 07/2022'}]   \n",
       "\n",
       "                                                                                                                                                                             Technical Skills  \\\n",
       "0  [NumPy, Pandas, Scikit-learn, Langchain, MySQL, Seaborn, TensorFlow, PowerBI, Python, Excel, Statistics, Data Analysis, Machine Learning, Deep Learning, LLMs, Hugging Face, Ollama, Groq]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  Projects  \\\n",
       "0  [{'Project Name': 'Motor Renewal Analytics', 'Description': 'Worked on different projects like Motor Renewal Analytics, Loss Ratio Analysis, Motor Fraud Detection. Built best Motor Fraud Detection Model outperforming existing model with 0.80 recall and 0.40 f1-score.'}, {'Project Name': 'Bureau Data Analysis', 'Description': 'Applied ML techniques to analyze bureau data from 120,000 users effectively reducing fraud risks. Engineered 1000 features using NumPy, Pandas, regex from OTP, SMS, Payday, and Fintech data present in MySQL database to reduce risk by adding these features to existing machine learning model and measuring the impact of new features.'}, {'Project Name': 'End-to-End ML Project for Water Potability', 'Description': 'Performed Preprocessing, EDA, Feature Engineering on data for making it model building ready. Utilized multiple data preprocessing techniques in imputation, imbalance handling, feature creation, etc. Performed null values imputation using Linear Regression with non-null columns to predicting null values. Built ML models like Logistic Regression, Decision Tree, KNN, Random Forest, SVM, Artificial Neural Network. Performed hyperparameter tuning using Grid Search CV resulting 0.72 F1 score.'}, {'Project Name': 'Stock Analyzing Using AI Agents', 'Description': 'Real-Time Market Intelligence Using Agent 1 to analyze industry-specific news ensuring timely stock market insights. Expert Stock Recommendations Using Agent 2 curates the top 5 stock picks based on AI-driven analysis. AI-Powered Workflow Leverages AI Agents Crew AI and Serper to automate stock research enhancing precision and efficiency. Seamless AI Integration Combines multi-agent collaboration to deliver a streamlined and intelligent stock recommendation experience.'}]   \n",
       "\n",
       "                                                                                                                                                                                             Education Details  \\\n",
       "0  [{'University Name': 'Maharishi University of Information Technology', 'Location': 'Noida, Delhi NCR', 'Degree': 'B.Tech Computer Science in Data Science', 'CGPA': '9.0', 'Graduation Date': 'June 2024'}]   \n",
       "\n",
       "                                                                                   Certifications  \n",
       "0  [{'Certification Name': 'Data Science Specialization', 'Issuing Organization': 'Internshala'}]  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = post_json_preprocess(res.content)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b48a3ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_input = 'https://www.naukri.com/job-listings-data-analytics-ernst-young-bengaluru-0-to-2-years-160425507082?src=seo_srp&sid=17449675885742309&xp=1&px=1'\n",
    "loader = WebBaseLoader([url_input])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "bdbe592b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "\n",
    "    text = re.sub(r\"\\n(?=\\w)\", \" \", text)\n",
    "    text = re.sub(r\"\\n\", \"\", text)\n",
    "    text = re.sub(r\"\\xa0\", \"\", text)\n",
    "    # # Remove HTML tags\n",
    "    # text = re.sub(r'<[^>]*?>', '', text)\n",
    "    # # Remove URLs\n",
    "    # # text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', '', text)\n",
    "    # # Remove dates\n",
    "    # text = re.sub(r'\\b\\d{2}/\\d{4}\\s*[\\u2013-]\\s*\\d{2}/\\d{4}\\b', '', text)\n",
    "    # # Remove special characters\n",
    "    # text = re.sub(r'[^a-zA-Z0-9 ]', '', text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    # text = re.sub(r'\\s{2,}', ' ', text)\n",
    "    # # Trim leading and trailing whitespace\n",
    "    # text = text.strip()\n",
    "    # # Remove extra whitespace\n",
    "    # text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "1fd98ec8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_content = clean_text(loader.load()[0].page_content)\n",
    "website_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "4198538d",
   "metadata": {},
   "outputs": [],
   "source": [
    "website_prompt_extract = PromptTemplate.from_template('''\n",
    "You are an AI bot designed to act as a professional for parsing job opening websites. You are given with website content and your job is to extract the following information from the content:\n",
    "\n",
    "1. Job Title\n",
    "2. Job Description\n",
    "3. Responsibilities\n",
    "4. Required Skills\n",
    "5. Qualification Required\n",
    "6. About the Company\n",
    "\n",
    "Website Content:\n",
    "{website_content}\n",
    "\n",
    "#Only return the valid text file format\n",
    "Example :\n",
    "Job Title\n",
    "Title of job\n",
    "\n",
    "NO PREAMBLE & Keep everything short, crisp and to the point.\n",
    "''')\n",
    "\n",
    "website_chain_extract = website_prompt_extract | llm\n",
    "job_description = website_chain_extract.invoke({\"website_content\": website_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ec68fd10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Job Title\\nJunior Machine Learning Engineer\\n\\nJob Description\\nBuilding machine learning based state-of-the-arts solutions for document understanding.\\n\\nResponsibilities\\nDesigning, fine tuning and developing solutions for document understanding, parsing key information from scanned documents, fixing/improving scanned document quality/resolution.\\n\\nRequired Skills\\nPython, OCR, computer vision, transformer based vision models, multi-modal models, TensorFlow, PyTorch, Django, Flask, Kafka, Spark, MongoDB.\\n\\nQualification Required\\n0-2 years of experience, strong Python skills, expertise in OCR and computer vision.\\n\\nAbout the Company\\nAutonomize AI, pioneering the use of AI to turn unstructured data into actionable insights for healthcare knowledge workers.'"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_description.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "4bbbdaf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Create the prompt template\n",
    "cover_letter_prompt_extract = PromptTemplate.from_template('''\n",
    "You are an AI bot designed to act as a professional for creating Cover Letter. You are given with Job Description and Candidate professional details,\n",
    "based on these two descriptions give details of the following information from the content:\n",
    "\n",
    "1. Asking for Job Opportunity\n",
    "2. Why I suits best for this role\n",
    "3. My skills relevant to job description \n",
    "4. My past experience relevant to job description\n",
    "5. How can I add value to the company\n",
    "6. My name, email, phone number with thank note \n",
    "\n",
    "Job description Content:\n",
    "{job_description}\n",
    "\n",
    "Candidate professional details:\n",
    "{resume_extract}\n",
    "\n",
    "#Only return the valid text file format\n",
    "\n",
    "Note : Maximum 200 words in the cover letter.\n",
    "Note : Not write anything exagerated from candidate professional details.\n",
    "Note : Focus on quantitative value to express my projects relevant to job description.\n",
    "\n",
    "NO PREAMBLE & Keep everything short, crisp and to the point.\n",
    "''')\n",
    "\n",
    "# Step 2: Create chain\n",
    "cover_letter_chain_extract = cover_letter_prompt_extract | llm\n",
    "\n",
    "# Step 3: Run the chain with the required inputs\n",
    "cover_letter_output = cover_letter_chain_extract.invoke({\n",
    "    \"job_description\": job_description,\n",
    "    \"resume_extract\": resume_extract\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "7aa82037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Dear Hiring Manager,\\n\\nI'm excited to apply for the Junior Machine Learning Engineer role at Autonomize AI. \\nI suit this role with my strong Python skills and expertise in machine learning.\\n\\nMy relevant skills include Python, TensorFlow, and computer vision. \\nIn my previous projects, I worked on Motor Renewal Analytics, achieving 0.80 recall and 0.40 f1 score, and developed an ML model using data from 6000 users.\\n\\nI can add value to the company by applying my ML skills to analyze data and develop effective solutions. \\nI'm confident my experience and skills make me a strong fit for this role.\\n\\nSincerely,\\nSaqib Alam Ansari\\nsaqibdatascience@gmail.com\\n91 9999473710\\nThank you for considering my application.\""
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cover_letter_output.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669212ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
